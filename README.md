# eval-web-service

The document below outlines the design decisions and explains the structure of the project and the behavior of its subparts. Also included are instructions for running the project and its tests, as well as example responses from the server and the web client.

## Architecture

### Interpreter architecture

For the implementation of the evaluator part of the task I've decided to take the approach of treating each sentence like a statement in a programming language. For this we first need to define how our laguage will look. We use the Backus-Naur form to define the structure of the statements in our language. 

```
<sentence> = <question><num>(<op><num>...)<pmark>
<question> = What is
<num> = 1 | 2 | 3 ...
<op> = plus | minus | multiplied by | divided by
<pmark> = ?
```

As we can see we have 5 distinct structures in our language. Let's examine each of them in more detail.
- `<sentence>` - the sentence represents a complete statement in our language. It can be evaluated to an exact number.
- `<question>` - the question represents the begining of a new statement. Currently the only supported question is "What is". Attempting to use any other question will result in a non-math question error.
- `<num>` - any natural number we want to include in our statement.
- `<op>` - the operation we want to perform on the left and right numbers in the statement. In case there are more than two numbers, the result of all the previous operaitons is taken as the left side of the operation.
 - `<pmark>` - a punctuation mark that signals the end of a statemant. Currently the only supported puncutation mark is a question mark.

Now that we've defined the structure of our language we need to interpret it. To do that our interpreter consists of three stages: a lexical analyzer (lexer), a syntax analyzer (parser) and a token interpreter.

The first part of the interpreting of our language is the lexical analyzer. During this stage the input statement is split into the tokens defined above. This is accomplished using regular expressions to match the next token in the input to any of the structural elements of the statement. Bellow a diagram of the state machine of the lexical analyzer. 

![lexer state machine](assets/lexer.drawio.svg)

- Tokenise state - the initial state of our state machine. If we encounter a supported token, a suppoted token event is called and the token is extracted from the input.
- Non-math question state - an end state of the state machine. A transition to this state is made in case we encounter an unsupported token. In this case a unsuppoter token event is issued. A predicate decides whether we enter this state or the unsuppoted token state. This predicate checks the current context of the lexer for a `<question>` token and in case there isn't any, we transition here.
- Unsupported token state - an end state of the state machine. A transition to this state is made in case we encounter an unsupported token. In this case a unsuppoter token event is issued. A predicate decides whether we enter this state or the non-math question state. This predicate checks the current context of the lexer for a `<question>` token and in case there is one, we transition here.
- EOF state - an end state of the state machine. A transition to this state is made in case ewe encounter a `<pmark>` token. A predicate decides whether we enter this state or the non-math question state based on whether the context of the state machine has a `<question>` token.

Each of the events is generated by reading the input and analyzing the current token using regex. In case we end up in any state different from EOF, an error is returned indicating that our statement doesn't follow the lexical rules of our language. 

The second part is the syntax analyzer. The syntax analyzer is an implementation of a LL parser meaning it reads tokens left-to-right and parses only the current token, without using a lookahead or trying to build more complex token trees. During this stage the statement is checked whether it follows the rules we've defined for our language i.e. whether it starts with a question, end with a question mark, has a number on each side of it's operands, etc. In case any of the rules isn't met, the syntax anylzer transitions to a syntax error state and returns an error. Bellow is a diagram of the state machine of the syntax analyzer.

![parser state machine](assets/parser.drawio.svg)

- Initial state - the initial state of out state machine. This state supports two state transitions. On a question event,a transition to the question state is made. On any other event we trasition to a syntax error state.
- Question state - After reading a token, the state machine transitions to this state. This state supports two transitions. On a number event a transition to the number state. On any other event we trasition to a syntax error state.
- Number state - After reading a number, the state machine transitions to this state. This state supports three transitions. On an operand event, a transition to the operand state is made. On a punctuation mark event, a transition to the final state is made. On any other event, we tranistion to the syntax error state.
- Operand state - After reading an operand, the state machine transitions to this state. This state supports two transitions. On a number event, a transition to the number state is made. On any other event we transition to the syntax error state.
- Syntax error state - a transition to this state is made in case the statement doesn't follow the defined syntax of our language. This is a final state, meaning it doesn't support any transitions. In case the state machine ends up in this state, the parser returns with an error. 
- Final state - this state signifies that we have reached the end of our statement. This is a final state meaning that it doesn't support any further transitions. If this state is reached the parser returns a list of the significant parsed tokens, that is then used as an input to the token interpreter.

Each event of the state machine is generated based on the list of tokens returned from the lexer e.g. a question token generates a question event, a number token generates a number event etc.

The syntax analyzer also makes a distinction between significant and nonsignificant tokens. Significant tokens are tokens used during the interpreting stage, while nonsignificant tokens are used only for the structuring of the statement. In our case the significant tokens are the `<num>` and `<op>` tokens, while the nonsignificat are the `<question>` and `<pmark>`. The syntax analyzer leaves only the significant tokens before handing them over to the interpreter stage.

The token interpreter if the final part of the evaluation. During this stage the tokens are interpreted and specific actions are performed based on the type of the tokens. The `<num>` token is parsed to it's integer representation and the `<op>` token determines the operation to be performed.

The interpreter also has unit tests. The tests are table-based and test each stage of the interpreter against different inputs. This approach has been chosen because the stages of the interpreters are implemented using state machines, so mocking and stubbing aren't applicable in this scenario.

Each of the stages of the interpreter is stateless, meaning it's just a function that takes an input and returns an output. The service interface for the interpreter on the other hand defines an interface for the interpreter consisting of three functions and supported errors. Because of this a middleware is implemented for the interpreter that complies to the interface by wrapping the functions and translating their errors to the ones defined in the service.


### Service architecture

The architecture of the service follows a hexagonal approach, in which the business logic is situated in the center of the application and defines interfaces for interacting with outside services. For this project, I've decided to take a new approach: instead of defining the adapter interfaces in the respective packages, they are defined in the package containing the business logic, thus emphasizing the hexagonal architecture of the application. The adapters then base their implementations on the interfaces defined in the business logic.

The idea behind this is to achieve a loose coupling between the business logic and the adapters and be able to easily switch between different adapter implementations if needed. Also, it is meant to emphasize that business logic should "drive" the direction in which the application is developed, while the adapters should "follow" those design choices and not the other way around.

## Project structure

## Running the application

### Running the server

### Running the client
